{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "daaad551",
   "metadata": {},
   "source": [
    "# Credit Card Defaulters Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45775e2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.10.0-cp39-cp39-win_amd64.whl (455.9 MB)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (3.19.4)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.27.0-cp39-cp39-win_amd64.whl (1.5 MB)\n",
      "Collecting libclang>=13.0.0\n",
      "  Downloading libclang-14.0.6-py2.py3-none-win_amd64.whl (14.2 MB)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Collecting flatbuffers>=2.0\n",
      "  Downloading flatbuffers-22.9.24-py2.py3-none-any.whl (26 kB)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting absl-py>=1.0.0\n",
      "  Downloading absl_py-1.2.0-py3-none-any.whl (123 kB)\n",
      "Collecting keras-preprocessing>=1.1.1\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Collecting tensorflow-estimator<2.11,>=2.10.0\n",
      "  Downloading tensorflow_estimator-2.10.0-py2.py3-none-any.whl (438 kB)\n",
      "Collecting keras<2.11,>=2.10.0\n",
      "  Downloading keras-2.10.0-py2.py3-none-any.whl (1.7 MB)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (58.0.4)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (3.10.0.2)\n",
      "Requirement already satisfied: packaging in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (21.0)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (3.2.1)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.12.1)\n",
      "Collecting tensorboard<2.11,>=2.10\n",
      "  Downloading tensorboard-2.10.1-py3-none-any.whl (5.9 MB)\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Downloading grpcio-1.49.1-cp39-cp39-win_amd64.whl (3.6 MB)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Collecting gast<=0.4.0,>=0.2.1\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.20.3)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Downloading termcolor-2.0.1-py3-none-any.whl (5.4 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.37.0)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.4.1-py3-none-any.whl (93 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.0.2)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-any.whl (2.4 kB)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.26.0)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.12.0-py2.py3-none-any.whl (169 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (5.0.0)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow) (4.8.1)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow) (3.6.0)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (3.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (1.26.7)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.1-py3-none-any.whl (151 kB)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from packaging->tensorflow) (3.0.4)\n",
      "Installing collected packages: pyasn1, rsa, pyasn1-modules, oauthlib, requests-oauthlib, google-auth, tensorboard-plugin-wit, tensorboard-data-server, markdown, grpcio, google-auth-oauthlib, absl-py, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard, opt-einsum, libclang, keras-preprocessing, keras, google-pasta, gast, flatbuffers, astunparse, tensorflow\n",
      "Successfully installed absl-py-1.2.0 astunparse-1.6.3 flatbuffers-22.9.24 gast-0.4.0 google-auth-2.12.0 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 grpcio-1.49.1 keras-2.10.0 keras-preprocessing-1.1.2 libclang-14.0.6 markdown-3.4.1 oauthlib-3.2.1 opt-einsum-3.3.0 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-oauthlib-1.3.1 rsa-4.9 tensorboard-2.10.1 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.10.0 tensorflow-estimator-2.10.0 tensorflow-io-gcs-filesystem-0.27.0 termcolor-2.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5be5fcc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in c:\\programdata\\anaconda3\\lib\\site-packages (2.10.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1728b19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83e2db48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.10.0'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c28d0a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from tensorflow import keras\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51b061dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tw_data = pd.read_csv(\"creditcarddefault.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7fd9bfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_0</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>...</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>default payment next month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>20000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>689</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>120000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3272</td>\n",
       "      <td>3455</td>\n",
       "      <td>3261</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>90000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>14331</td>\n",
       "      <td>14948</td>\n",
       "      <td>15549</td>\n",
       "      <td>1518</td>\n",
       "      <td>1500</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>50000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>28314</td>\n",
       "      <td>28959</td>\n",
       "      <td>29547</td>\n",
       "      <td>2000</td>\n",
       "      <td>2019</td>\n",
       "      <td>1200</td>\n",
       "      <td>1100</td>\n",
       "      <td>1069</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>50000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>20940</td>\n",
       "      <td>19146</td>\n",
       "      <td>19131</td>\n",
       "      <td>2000</td>\n",
       "      <td>36681</td>\n",
       "      <td>10000</td>\n",
       "      <td>9000</td>\n",
       "      <td>689</td>\n",
       "      <td>679</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE  PAY_0  PAY_2  PAY_3  PAY_4  \\\n",
       "0   1      20000    2          2         1   24      2      2     -1     -1   \n",
       "1   2     120000    2          2         2   26     -1      2      0      0   \n",
       "2   3      90000    2          2         2   34      0      0      0      0   \n",
       "3   4      50000    2          2         1   37      0      0      0      0   \n",
       "4   5      50000    1          2         1   57     -1      0     -1      0   \n",
       "\n",
       "   ...  BILL_AMT4  BILL_AMT5  BILL_AMT6  PAY_AMT1  PAY_AMT2  PAY_AMT3  \\\n",
       "0  ...          0          0          0         0       689         0   \n",
       "1  ...       3272       3455       3261         0      1000      1000   \n",
       "2  ...      14331      14948      15549      1518      1500      1000   \n",
       "3  ...      28314      28959      29547      2000      2019      1200   \n",
       "4  ...      20940      19146      19131      2000     36681     10000   \n",
       "\n",
       "   PAY_AMT4  PAY_AMT5  PAY_AMT6  default payment next month  \n",
       "0         0         0         0                           1  \n",
       "1      1000         0      2000                           1  \n",
       "2      1000      1000      5000                           0  \n",
       "3      1100      1069      1000                           0  \n",
       "4      9000       689       679                           0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5300bc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_0</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>...</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>default payment next month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29995</th>\n",
       "      <td>29996</td>\n",
       "      <td>220000</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>88004</td>\n",
       "      <td>31237</td>\n",
       "      <td>15980</td>\n",
       "      <td>8500</td>\n",
       "      <td>20000</td>\n",
       "      <td>5003</td>\n",
       "      <td>3047</td>\n",
       "      <td>5000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29996</th>\n",
       "      <td>29997</td>\n",
       "      <td>150000</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>43</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>8979</td>\n",
       "      <td>5190</td>\n",
       "      <td>0</td>\n",
       "      <td>1837</td>\n",
       "      <td>3526</td>\n",
       "      <td>8998</td>\n",
       "      <td>129</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29997</th>\n",
       "      <td>29998</td>\n",
       "      <td>30000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>20878</td>\n",
       "      <td>20582</td>\n",
       "      <td>19357</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22000</td>\n",
       "      <td>4200</td>\n",
       "      <td>2000</td>\n",
       "      <td>3100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29998</th>\n",
       "      <td>29999</td>\n",
       "      <td>80000</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>52774</td>\n",
       "      <td>11855</td>\n",
       "      <td>48944</td>\n",
       "      <td>85900</td>\n",
       "      <td>3409</td>\n",
       "      <td>1178</td>\n",
       "      <td>1926</td>\n",
       "      <td>52964</td>\n",
       "      <td>1804</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29999</th>\n",
       "      <td>30000</td>\n",
       "      <td>50000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>36535</td>\n",
       "      <td>32428</td>\n",
       "      <td>15313</td>\n",
       "      <td>2078</td>\n",
       "      <td>1800</td>\n",
       "      <td>1430</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID  LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE  PAY_0  PAY_2  PAY_3  \\\n",
       "29995  29996     220000    1          3         1   39      0      0      0   \n",
       "29996  29997     150000    1          3         2   43     -1     -1     -1   \n",
       "29997  29998      30000    1          2         2   37      4      3      2   \n",
       "29998  29999      80000    1          3         1   41      1     -1      0   \n",
       "29999  30000      50000    1          2         1   46      0      0      0   \n",
       "\n",
       "       PAY_4  ...  BILL_AMT4  BILL_AMT5  BILL_AMT6  PAY_AMT1  PAY_AMT2  \\\n",
       "29995      0  ...      88004      31237      15980      8500     20000   \n",
       "29996     -1  ...       8979       5190          0      1837      3526   \n",
       "29997     -1  ...      20878      20582      19357         0         0   \n",
       "29998      0  ...      52774      11855      48944     85900      3409   \n",
       "29999      0  ...      36535      32428      15313      2078      1800   \n",
       "\n",
       "       PAY_AMT3  PAY_AMT4  PAY_AMT5  PAY_AMT6  default payment next month  \n",
       "29995      5003      3047      5000      1000                           0  \n",
       "29996      8998       129         0         0                           0  \n",
       "29997     22000      4200      2000      3100                           1  \n",
       "29998      1178      1926     52964      1804                           1  \n",
       "29999      1430      1000      1000      1000                           1  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tw_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b1e5b971",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_0</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>...</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>default payment next month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>3.000000e+04</td>\n",
       "      <td>30000.00000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>15000.500000</td>\n",
       "      <td>167484.322667</td>\n",
       "      <td>1.603733</td>\n",
       "      <td>1.853133</td>\n",
       "      <td>1.551867</td>\n",
       "      <td>35.485500</td>\n",
       "      <td>-0.016700</td>\n",
       "      <td>-0.133767</td>\n",
       "      <td>-0.166200</td>\n",
       "      <td>-0.220667</td>\n",
       "      <td>...</td>\n",
       "      <td>43262.948967</td>\n",
       "      <td>40311.400967</td>\n",
       "      <td>38871.760400</td>\n",
       "      <td>5663.580500</td>\n",
       "      <td>5.921163e+03</td>\n",
       "      <td>5225.68150</td>\n",
       "      <td>4826.076867</td>\n",
       "      <td>4799.387633</td>\n",
       "      <td>5215.502567</td>\n",
       "      <td>0.221200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8660.398374</td>\n",
       "      <td>129747.661567</td>\n",
       "      <td>0.489129</td>\n",
       "      <td>0.790349</td>\n",
       "      <td>0.521970</td>\n",
       "      <td>9.217904</td>\n",
       "      <td>1.123802</td>\n",
       "      <td>1.197186</td>\n",
       "      <td>1.196868</td>\n",
       "      <td>1.169139</td>\n",
       "      <td>...</td>\n",
       "      <td>64332.856134</td>\n",
       "      <td>60797.155770</td>\n",
       "      <td>59554.107537</td>\n",
       "      <td>16563.280354</td>\n",
       "      <td>2.304087e+04</td>\n",
       "      <td>17606.96147</td>\n",
       "      <td>15666.159744</td>\n",
       "      <td>15278.305679</td>\n",
       "      <td>17777.465775</td>\n",
       "      <td>0.415062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-170000.000000</td>\n",
       "      <td>-81334.000000</td>\n",
       "      <td>-339603.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7500.750000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2326.750000</td>\n",
       "      <td>1763.000000</td>\n",
       "      <td>1256.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>8.330000e+02</td>\n",
       "      <td>390.00000</td>\n",
       "      <td>296.000000</td>\n",
       "      <td>252.500000</td>\n",
       "      <td>117.750000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>15000.500000</td>\n",
       "      <td>140000.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>19052.000000</td>\n",
       "      <td>18104.500000</td>\n",
       "      <td>17071.000000</td>\n",
       "      <td>2100.000000</td>\n",
       "      <td>2.009000e+03</td>\n",
       "      <td>1800.00000</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>22500.250000</td>\n",
       "      <td>240000.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>54506.000000</td>\n",
       "      <td>50190.500000</td>\n",
       "      <td>49198.250000</td>\n",
       "      <td>5006.000000</td>\n",
       "      <td>5.000000e+03</td>\n",
       "      <td>4505.00000</td>\n",
       "      <td>4013.250000</td>\n",
       "      <td>4031.500000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>30000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>891586.000000</td>\n",
       "      <td>927171.000000</td>\n",
       "      <td>961664.000000</td>\n",
       "      <td>873552.000000</td>\n",
       "      <td>1.684259e+06</td>\n",
       "      <td>896040.00000</td>\n",
       "      <td>621000.000000</td>\n",
       "      <td>426529.000000</td>\n",
       "      <td>528666.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ID       LIMIT_BAL           SEX     EDUCATION      MARRIAGE  \\\n",
       "count  30000.000000    30000.000000  30000.000000  30000.000000  30000.000000   \n",
       "mean   15000.500000   167484.322667      1.603733      1.853133      1.551867   \n",
       "std     8660.398374   129747.661567      0.489129      0.790349      0.521970   \n",
       "min        1.000000    10000.000000      1.000000      0.000000      0.000000   \n",
       "25%     7500.750000    50000.000000      1.000000      1.000000      1.000000   \n",
       "50%    15000.500000   140000.000000      2.000000      2.000000      2.000000   \n",
       "75%    22500.250000   240000.000000      2.000000      2.000000      2.000000   \n",
       "max    30000.000000  1000000.000000      2.000000      6.000000      3.000000   \n",
       "\n",
       "                AGE         PAY_0         PAY_2         PAY_3         PAY_4  \\\n",
       "count  30000.000000  30000.000000  30000.000000  30000.000000  30000.000000   \n",
       "mean      35.485500     -0.016700     -0.133767     -0.166200     -0.220667   \n",
       "std        9.217904      1.123802      1.197186      1.196868      1.169139   \n",
       "min       21.000000     -2.000000     -2.000000     -2.000000     -2.000000   \n",
       "25%       28.000000     -1.000000     -1.000000     -1.000000     -1.000000   \n",
       "50%       34.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%       41.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max       79.000000      8.000000      8.000000      8.000000      8.000000   \n",
       "\n",
       "       ...      BILL_AMT4      BILL_AMT5      BILL_AMT6       PAY_AMT1  \\\n",
       "count  ...   30000.000000   30000.000000   30000.000000   30000.000000   \n",
       "mean   ...   43262.948967   40311.400967   38871.760400    5663.580500   \n",
       "std    ...   64332.856134   60797.155770   59554.107537   16563.280354   \n",
       "min    ... -170000.000000  -81334.000000 -339603.000000       0.000000   \n",
       "25%    ...    2326.750000    1763.000000    1256.000000    1000.000000   \n",
       "50%    ...   19052.000000   18104.500000   17071.000000    2100.000000   \n",
       "75%    ...   54506.000000   50190.500000   49198.250000    5006.000000   \n",
       "max    ...  891586.000000  927171.000000  961664.000000  873552.000000   \n",
       "\n",
       "           PAY_AMT2      PAY_AMT3       PAY_AMT4       PAY_AMT5  \\\n",
       "count  3.000000e+04   30000.00000   30000.000000   30000.000000   \n",
       "mean   5.921163e+03    5225.68150    4826.076867    4799.387633   \n",
       "std    2.304087e+04   17606.96147   15666.159744   15278.305679   \n",
       "min    0.000000e+00       0.00000       0.000000       0.000000   \n",
       "25%    8.330000e+02     390.00000     296.000000     252.500000   \n",
       "50%    2.009000e+03    1800.00000    1500.000000    1500.000000   \n",
       "75%    5.000000e+03    4505.00000    4013.250000    4031.500000   \n",
       "max    1.684259e+06  896040.00000  621000.000000  426529.000000   \n",
       "\n",
       "            PAY_AMT6  default payment next month  \n",
       "count   30000.000000                30000.000000  \n",
       "mean     5215.502567                    0.221200  \n",
       "std     17777.465775                    0.415062  \n",
       "min         0.000000                    0.000000  \n",
       "25%       117.750000                    0.000000  \n",
       "50%      1500.000000                    0.000000  \n",
       "75%      4000.000000                    0.000000  \n",
       "max    528666.000000                    1.000000  \n",
       "\n",
       "[8 rows x 25 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tw_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4aa8039a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 25)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tw_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce912fdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30000 entries, 0 to 29999\n",
      "Data columns (total 25 columns):\n",
      " #   Column                      Non-Null Count  Dtype\n",
      "---  ------                      --------------  -----\n",
      " 0   ID                          30000 non-null  int64\n",
      " 1   LIMIT_BAL                   30000 non-null  int64\n",
      " 2   SEX                         30000 non-null  int64\n",
      " 3   EDUCATION                   30000 non-null  int64\n",
      " 4   MARRIAGE                    30000 non-null  int64\n",
      " 5   AGE                         30000 non-null  int64\n",
      " 6   PAY_0                       30000 non-null  int64\n",
      " 7   PAY_2                       30000 non-null  int64\n",
      " 8   PAY_3                       30000 non-null  int64\n",
      " 9   PAY_4                       30000 non-null  int64\n",
      " 10  PAY_5                       30000 non-null  int64\n",
      " 11  PAY_6                       30000 non-null  int64\n",
      " 12  BILL_AMT1                   30000 non-null  int64\n",
      " 13  BILL_AMT2                   30000 non-null  int64\n",
      " 14  BILL_AMT3                   30000 non-null  int64\n",
      " 15  BILL_AMT4                   30000 non-null  int64\n",
      " 16  BILL_AMT5                   30000 non-null  int64\n",
      " 17  BILL_AMT6                   30000 non-null  int64\n",
      " 18  PAY_AMT1                    30000 non-null  int64\n",
      " 19  PAY_AMT2                    30000 non-null  int64\n",
      " 20  PAY_AMT3                    30000 non-null  int64\n",
      " 21  PAY_AMT4                    30000 non-null  int64\n",
      " 22  PAY_AMT5                    30000 non-null  int64\n",
      " 23  PAY_AMT6                    30000 non-null  int64\n",
      " 24  default payment next month  30000 non-null  int64\n",
      "dtypes: int64(25)\n",
      "memory usage: 5.7 MB\n"
     ]
    }
   ],
   "source": [
    "tw_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93f69f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 20000      2      2 ...      0      0      0]\n",
      " [120000      2      2 ...   1000      0   2000]\n",
      " [ 90000      2      2 ...   1000   1000   5000]\n",
      " ...\n",
      " [ 30000      1      2 ...   4200   2000   3100]\n",
      " [ 80000      1      3 ...   1926  52964   1804]\n",
      " [ 50000      1      2 ...   1000   1000   1000]]\n",
      "[1 1 0 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# removing the customer id and name and saving the dependent variables in x\n",
    "x = tw_data.iloc[:,1:24].values\n",
    "\n",
    "# saving the independent variable in y\n",
    "y = tw_data.iloc[:,24].values\n",
    "\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dd462142",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 23)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "61e0397d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21000, 23)\n",
      "(21000,)\n",
      "(9000, 23)\n",
      "(9000,)\n"
     ]
    }
   ],
   "source": [
    "# splitting the data set into train and test using train_test_split library for cross validation\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state = 111)\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b984f816",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling the data using the preprocessing library\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "x_train = sc.fit_transform(x_train)\n",
    "x_test = sc.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ddd4ba42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.48238852,  0.81447304,  0.18907673,  0.86211952, -0.48921975,\n",
       "        -0.87463676, -0.72347864, -0.6983838 , -0.66637051,  0.23416564,\n",
       "         0.25233359, -0.63042993, -0.63367788, -0.6645842 , -0.51248219,\n",
       "        -0.57038965,  0.39521137, -0.0821721 , -0.22758026,  0.33473587,\n",
       "        -0.28260403,  3.38918769, -0.15149706]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bae0b8e",
   "metadata": {},
   "source": [
    "# Model Building Using Keras\n",
    "We have so far understood the data and made some preprocessing on the data in order to make the data suitable for our model. Now that are data is ready to be trained let us build our first keras model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7acb9baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing required modules from keras\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b892729d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: initializing our model\n",
    "class_model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d169dbe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Adding the layers to our NN.\n",
    "# -> In this we add one I/P layer (which are the IPS directly), multiple hidden layers and 1 O/P layer.\n",
    "# -> As there are 23 input variables there will be 23 nodes in the input layer. \n",
    "# -> Nodes in the hidden there is free to our choice, however to have an optimum error \n",
    "# -> We can calculate the nodes in our first hidden layer to be (I/P nodes + 1) / 2 = (23 + 1)/ 2 = 12\n",
    "\n",
    "# -> While initializing random weights to the NN, we pass the vlaue to the hyperparameter init as \"UNIFORM\"\n",
    "# -> UNIFORM will ensure that the weights are given uniformly random and close to 0\n",
    "\n",
    "# -> Also we should be specifying what activation function to be used. Let us use RELU in our model here \n",
    "\n",
    "# 1st HIDDEN LAYER\n",
    "class_model.add(Dense(24, input_dim = 23, activation = \"relu\"))\n",
    "\n",
    "# 2nd HIDDEN LAYER\n",
    "# as the input dim to this layer is the output from the previous layer \n",
    "# we need not explicitly specify it here \n",
    "class_model.add(Dense(12, activation = \"relu\"))\n",
    "\n",
    "# OUTPUT LAYER\n",
    "# sigmoid activation is used to get the output between 0 and 1.\n",
    "class_model.add(Dense(1, activation = \"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4f8cb512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 24)                576       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 12)                300       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 889\n",
      "Trainable params: 889\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "class_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eb6a8da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Compiling the neural network\n",
    "# In this step we have the liberty to choose the optimization method we would like to use\n",
    "# the loss function and the metrics that we require output\n",
    "# binary_crossentropy loss function used when a binary output is expected\n",
    "\n",
    "class_model.compile(optimizer = \"adam\", loss = \"binary_crossentropy\", metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "31585b74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2100/2100 [==============================] - 7s 1ms/step - loss: 0.4736 - accuracy: 0.8033\n",
      "Epoch 2/100\n",
      "2100/2100 [==============================] - 4s 2ms/step - loss: 0.4435 - accuracy: 0.8165\n",
      "Epoch 3/100\n",
      "2100/2100 [==============================] - 3s 1ms/step - loss: 0.4368 - accuracy: 0.8183\n",
      "Epoch 4/100\n",
      "2100/2100 [==============================] - 2s 1ms/step - loss: 0.4336 - accuracy: 0.8192\n",
      "Epoch 5/100\n",
      "2100/2100 [==============================] - 2s 1ms/step - loss: 0.4314 - accuracy: 0.8199\n",
      "Epoch 6/100\n",
      "2100/2100 [==============================] - 3s 1ms/step - loss: 0.4303 - accuracy: 0.8209\n",
      "Epoch 7/100\n",
      "2100/2100 [==============================] - 3s 1ms/step - loss: 0.4285 - accuracy: 0.8206\n",
      "Epoch 8/100\n",
      "2100/2100 [==============================] - 3s 1ms/step - loss: 0.4268 - accuracy: 0.8200\n",
      "Epoch 9/100\n",
      "2100/2100 [==============================] - 3s 1ms/step - loss: 0.4258 - accuracy: 0.8223\n",
      "Epoch 10/100\n",
      "2100/2100 [==============================] - 2s 1ms/step - loss: 0.4254 - accuracy: 0.8211\n",
      "Epoch 11/100\n",
      "2100/2100 [==============================] - 3s 1ms/step - loss: 0.4247 - accuracy: 0.8205\n",
      "Epoch 12/100\n",
      "2100/2100 [==============================] - 3s 2ms/step - loss: 0.4236 - accuracy: 0.8210\n",
      "Epoch 13/100\n",
      "2100/2100 [==============================] - 4s 2ms/step - loss: 0.4231 - accuracy: 0.8208\n",
      "Epoch 14/100\n",
      "2100/2100 [==============================] - 4s 2ms/step - loss: 0.4221 - accuracy: 0.8224\n",
      "Epoch 15/100\n",
      "2100/2100 [==============================] - 4s 2ms/step - loss: 0.4212 - accuracy: 0.8221\n",
      "Epoch 16/100\n",
      "2100/2100 [==============================] - 4s 2ms/step - loss: 0.4205 - accuracy: 0.8207\n",
      "Epoch 17/100\n",
      "2100/2100 [==============================] - 3s 1ms/step - loss: 0.4205 - accuracy: 0.8226\n",
      "Epoch 18/100\n",
      "2100/2100 [==============================] - 3s 1ms/step - loss: 0.4195 - accuracy: 0.8221\n",
      "Epoch 19/100\n",
      "2100/2100 [==============================] - 3s 1ms/step - loss: 0.4190 - accuracy: 0.8220\n",
      "Epoch 20/100\n",
      "2100/2100 [==============================] - 3s 1ms/step - loss: 0.4185 - accuracy: 0.8221\n",
      "Epoch 21/100\n",
      "2100/2100 [==============================] - 3s 1ms/step - loss: 0.4183 - accuracy: 0.8225\n",
      "Epoch 22/100\n",
      "2100/2100 [==============================] - 3s 1ms/step - loss: 0.4181 - accuracy: 0.8214\n",
      "Epoch 23/100\n",
      "2100/2100 [==============================] - 4s 2ms/step - loss: 0.4179 - accuracy: 0.8230\n",
      "Epoch 24/100\n",
      "2100/2100 [==============================] - 4s 2ms/step - loss: 0.4169 - accuracy: 0.8225\n",
      "Epoch 25/100\n",
      "2100/2100 [==============================] - 4s 2ms/step - loss: 0.4160 - accuracy: 0.8237\n",
      "Epoch 26/100\n",
      "2100/2100 [==============================] - 4s 2ms/step - loss: 0.4158 - accuracy: 0.8244\n",
      "Epoch 27/100\n",
      "2100/2100 [==============================] - 4s 2ms/step - loss: 0.4153 - accuracy: 0.8237\n",
      "Epoch 28/100\n",
      "2100/2100 [==============================] - 4s 2ms/step - loss: 0.4154 - accuracy: 0.8234\n",
      "Epoch 29/100\n",
      "2100/2100 [==============================] - 4s 2ms/step - loss: 0.4151 - accuracy: 0.8244\n",
      "Epoch 30/100\n",
      "2100/2100 [==============================] - 3s 2ms/step - loss: 0.4146 - accuracy: 0.8236\n",
      "Epoch 31/100\n",
      "2100/2100 [==============================] - 3s 1ms/step - loss: 0.4138 - accuracy: 0.8250\n",
      "Epoch 32/100\n",
      "2100/2100 [==============================] - 3s 1ms/step - loss: 0.4136 - accuracy: 0.8246\n",
      "Epoch 33/100\n",
      "2100/2100 [==============================] - 3s 1ms/step - loss: 0.4132 - accuracy: 0.8245\n",
      "Epoch 34/100\n",
      "2100/2100 [==============================] - 3s 1ms/step - loss: 0.4132 - accuracy: 0.8245\n",
      "Epoch 35/100\n",
      "2100/2100 [==============================] - 3s 1ms/step - loss: 0.4126 - accuracy: 0.8238\n",
      "Epoch 36/100\n",
      "2100/2100 [==============================] - 3s 1ms/step - loss: 0.4126 - accuracy: 0.8249\n",
      "Epoch 37/100\n",
      "2100/2100 [==============================] - 3s 1ms/step - loss: 0.4121 - accuracy: 0.8240\n",
      "Epoch 38/100\n",
      "2100/2100 [==============================] - 3s 1ms/step - loss: 0.4116 - accuracy: 0.8242\n",
      "Epoch 39/100\n",
      "2100/2100 [==============================] - 3s 1ms/step - loss: 0.4121 - accuracy: 0.8250\n",
      "Epoch 40/100\n",
      "2100/2100 [==============================] - 3s 1ms/step - loss: 0.4115 - accuracy: 0.8243\n",
      "Epoch 41/100\n",
      "2100/2100 [==============================] - 3s 1ms/step - loss: 0.4111 - accuracy: 0.8242\n",
      "Epoch 42/100\n",
      "2100/2100 [==============================] - 3s 1ms/step - loss: 0.4109 - accuracy: 0.8249\n",
      "Epoch 43/100\n",
      "2100/2100 [==============================] - 3s 1ms/step - loss: 0.4113 - accuracy: 0.8239\n",
      "Epoch 44/100\n",
      "2100/2100 [==============================] - 3s 1ms/step - loss: 0.4100 - accuracy: 0.8256\n",
      "Epoch 45/100\n",
      "2100/2100 [==============================] - 3s 1ms/step - loss: 0.4102 - accuracy: 0.8245\n",
      "Epoch 46/100\n",
      "2100/2100 [==============================] - 3s 1ms/step - loss: 0.4088 - accuracy: 0.8262\n",
      "Epoch 47/100\n",
      "2100/2100 [==============================] - 3s 1ms/step - loss: 0.4096 - accuracy: 0.8245\n",
      "Epoch 48/100\n",
      "2100/2100 [==============================] - 3s 1ms/step - loss: 0.4095 - accuracy: 0.8250\n",
      "Epoch 49/100\n",
      "2100/2100 [==============================] - 3s 1ms/step - loss: 0.4094 - accuracy: 0.8254\n",
      "Epoch 50/100\n",
      "2100/2100 [==============================] - 3s 1ms/step - loss: 0.4094 - accuracy: 0.8260\n",
      "Epoch 51/100\n",
      "2100/2100 [==============================] - 3s 1ms/step - loss: 0.4090 - accuracy: 0.8252\n",
      "Epoch 52/100\n",
      "2100/2100 [==============================] - 3s 1ms/step - loss: 0.4089 - accuracy: 0.8245\n",
      "Epoch 53/100\n",
      "2100/2100 [==============================] - 3s 1ms/step - loss: 0.4082 - accuracy: 0.8271\n",
      "Epoch 54/100\n",
      "2100/2100 [==============================] - 3s 1ms/step - loss: 0.4079 - accuracy: 0.8247\n",
      "Epoch 55/100\n",
      "2100/2100 [==============================] - 3s 1ms/step - loss: 0.4083 - accuracy: 0.8243\n",
      "Epoch 56/100\n",
      "2100/2100 [==============================] - 3s 1ms/step - loss: 0.4074 - accuracy: 0.8256\n",
      "Epoch 57/100\n",
      "2100/2100 [==============================] - 3s 1ms/step - loss: 0.4074 - accuracy: 0.8262\n",
      "Epoch 58/100\n",
      "2100/2100 [==============================] - 3s 1ms/step - loss: 0.4072 - accuracy: 0.8254\n",
      "Epoch 59/100\n",
      "2100/2100 [==============================] - 3s 1ms/step - loss: 0.4077 - accuracy: 0.8249\n",
      "Epoch 60/100\n",
      "2100/2100 [==============================] - 3s 1ms/step - loss: 0.4073 - accuracy: 0.8263\n",
      "Epoch 61/100\n",
      "2100/2100 [==============================] - 3s 1ms/step - loss: 0.4068 - accuracy: 0.8266\n",
      "Epoch 62/100\n",
      "2100/2100 [==============================] - 3s 1ms/step - loss: 0.4060 - accuracy: 0.8271\n",
      "Epoch 63/100\n",
      "2100/2100 [==============================] - 3s 1ms/step - loss: 0.4063 - accuracy: 0.8260\n",
      "Epoch 64/100\n",
      "2100/2100 [==============================] - 3s 2ms/step - loss: 0.4071 - accuracy: 0.8270\n",
      "Epoch 65/100\n",
      "2100/2100 [==============================] - 3s 1ms/step - loss: 0.4065 - accuracy: 0.8247\n",
      "Epoch 66/100\n",
      "2100/2100 [==============================] - 3s 1ms/step - loss: 0.4065 - accuracy: 0.8267\n",
      "Epoch 67/100\n",
      "2100/2100 [==============================] - 3s 1ms/step - loss: 0.4062 - accuracy: 0.8270\n",
      "Epoch 68/100\n",
      "2100/2100 [==============================] - 3s 1ms/step - loss: 0.4056 - accuracy: 0.8274\n",
      "Epoch 69/100\n",
      "2100/2100 [==============================] - 3s 1ms/step - loss: 0.4053 - accuracy: 0.8270\n",
      "Epoch 70/100\n",
      "2100/2100 [==============================] - 3s 1ms/step - loss: 0.4054 - accuracy: 0.8268\n",
      "Epoch 71/100\n",
      "2100/2100 [==============================] - 3s 1ms/step - loss: 0.4053 - accuracy: 0.8265\n",
      "Epoch 72/100\n",
      "2100/2100 [==============================] - 3s 1ms/step - loss: 0.4046 - accuracy: 0.8271\n",
      "Epoch 73/100\n",
      "2100/2100 [==============================] - 3s 1ms/step - loss: 0.4052 - accuracy: 0.8267\n",
      "Epoch 74/100\n",
      "2100/2100 [==============================] - 3s 1ms/step - loss: 0.4051 - accuracy: 0.8272\n",
      "Epoch 75/100\n",
      "2100/2100 [==============================] - 3s 1ms/step - loss: 0.4045 - accuracy: 0.8269\n",
      "Epoch 76/100\n",
      "2100/2100 [==============================] - 3s 1ms/step - loss: 0.4042 - accuracy: 0.8277\n",
      "Epoch 77/100\n",
      "2100/2100 [==============================] - 3s 1ms/step - loss: 0.4045 - accuracy: 0.8274\n",
      "Epoch 78/100\n",
      "2100/2100 [==============================] - 3s 1ms/step - loss: 0.4047 - accuracy: 0.8270\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2100/2100 [==============================] - 2s 1ms/step - loss: 0.4045 - accuracy: 0.8267\n",
      "Epoch 80/100\n",
      "2100/2100 [==============================] - 2s 1ms/step - loss: 0.4039 - accuracy: 0.8265\n",
      "Epoch 81/100\n",
      "2100/2100 [==============================] - 2s 1ms/step - loss: 0.4036 - accuracy: 0.8268\n",
      "Epoch 82/100\n",
      "2100/2100 [==============================] - 3s 1ms/step - loss: 0.4040 - accuracy: 0.8280\n",
      "Epoch 83/100\n",
      "2100/2100 [==============================] - 2s 1ms/step - loss: 0.4036 - accuracy: 0.8280\n",
      "Epoch 84/100\n",
      "2100/2100 [==============================] - 3s 1ms/step - loss: 0.4035 - accuracy: 0.8279\n",
      "Epoch 85/100\n",
      "2100/2100 [==============================] - 2s 1ms/step - loss: 0.4034 - accuracy: 0.8272\n",
      "Epoch 86/100\n",
      "2100/2100 [==============================] - 2s 1ms/step - loss: 0.4033 - accuracy: 0.8278\n",
      "Epoch 87/100\n",
      "2100/2100 [==============================] - 2s 1ms/step - loss: 0.4027 - accuracy: 0.8288\n",
      "Epoch 88/100\n",
      "2100/2100 [==============================] - 3s 1ms/step - loss: 0.4025 - accuracy: 0.8284\n",
      "Epoch 89/100\n",
      "2100/2100 [==============================] - 3s 1ms/step - loss: 0.4022 - accuracy: 0.8271\n",
      "Epoch 90/100\n",
      "2100/2100 [==============================] - 3s 1ms/step - loss: 0.4030 - accuracy: 0.8267\n",
      "Epoch 91/100\n",
      "2100/2100 [==============================] - 2s 1ms/step - loss: 0.4031 - accuracy: 0.8288\n",
      "Epoch 92/100\n",
      "2100/2100 [==============================] - 2s 1ms/step - loss: 0.4019 - accuracy: 0.8287\n",
      "Epoch 93/100\n",
      "2100/2100 [==============================] - 2s 1ms/step - loss: 0.4019 - accuracy: 0.8288\n",
      "Epoch 94/100\n",
      "2100/2100 [==============================] - 3s 1ms/step - loss: 0.4016 - accuracy: 0.8289\n",
      "Epoch 95/100\n",
      "2100/2100 [==============================] - 3s 2ms/step - loss: 0.4012 - accuracy: 0.8283\n",
      "Epoch 96/100\n",
      "2100/2100 [==============================] - 4s 2ms/step - loss: 0.4019 - accuracy: 0.8273\n",
      "Epoch 97/100\n",
      "2100/2100 [==============================] - 4s 2ms/step - loss: 0.4014 - accuracy: 0.8276\n",
      "Epoch 98/100\n",
      "2100/2100 [==============================] - 4s 2ms/step - loss: 0.4022 - accuracy: 0.8278\n",
      "Epoch 99/100\n",
      "2100/2100 [==============================] - 4s 2ms/step - loss: 0.4009 - accuracy: 0.8287\n",
      "Epoch 100/100\n",
      "2100/2100 [==============================] - 4s 2ms/step - loss: 0.4009 - accuracy: 0.8283\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x29526425f10>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 4: Fitting the model\n",
    "\n",
    "class_model.fit(x_train, y_train, batch_size = 10, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f112ff11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "282/282 [==============================] - 3s 986us/step\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Predicting the result for the test data\n",
    "\n",
    "y_pred = class_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "447d2efa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.2757109 ],\n",
       "       [0.04824891],\n",
       "       [0.09008387],\n",
       "       ...,\n",
       "       [0.01904537],\n",
       "       [0.4543127 ],\n",
       "       [0.18311828]], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6b345aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As the values are the probability we may need to set up a threshold to find the actual values\n",
    "\n",
    "pred = (y_pred > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dd501d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names = [\"no\", \"yes\"]\n",
    "def plot_confusion_mat(cm, classes, \n",
    "                       normalize = False, \n",
    "                       title = \"Confusion Matrix\", cmap = plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting normalize = True.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation = \"nearest\", cmap = cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation = 45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    \n",
    "    if normalize:\n",
    "        cm = cm.astype(\"float\") / cm.sum(axis = 1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print(\"Confusion matri, without normalization\")\n",
    "        \n",
    "    print(cm)\n",
    "    \n",
    "    thresh = cm.max()/2\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                horizontalalignment = \"center\",\n",
    "                color = \"white\" if cm[i, j] > thresh else \"black\")\n",
    "        plt.tight_layout()\n",
    "        plt.ylabel(\"True\")\n",
    "        plt.xlabel(\"Predicted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b6e083d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matri, without normalization\n",
      "[[6584  396]\n",
      " [1324  696]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# formulating the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, pred)\n",
    "\n",
    "plt.figure()\n",
    "plot_confusion_mat(cm, classes = target_names, normalize = False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0bcbb9b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "282/282 [==============================] - 3s 1ms/step - loss: 0.4579 - accuracy: 0.8089\n",
      "\n",
      "ACCURACY: 80.89%\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the Model\n",
    "\n",
    "scores = class_model.evaluate(x_test, y_test)\n",
    "\n",
    "print(\"\\nACCURACY: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4951f72",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "Thus we have built our first model with Keras with 81% accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51fe8b0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
